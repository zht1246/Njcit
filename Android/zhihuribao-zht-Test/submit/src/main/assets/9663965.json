{
  "body": "<div class=\"main-wrap content-wrap\">\n<div class=\"headline\">\n\n<div class=\"img-place-holder\"><\/div>\n\n\n\n<\/div>\n\n<div class=\"content-inner\">\n\n\n\n\n<div class=\"question\">\n<h2 class=\"question-title\">2018 年应届硕士毕业生如何拿到知名互联网公司深度学习 offer？<\/h2>\n\n<div class=\"answer\">\n\n<div class=\"meta\">\n<img class=\"avatar\" src=\"http:\/\/pic1.zhimg.com\/06fde75d4_is.jpg\">\n<span class=\"author\">熊风，<\/span><span class=\"bio\">HKUST CS MPhil , 计算机视觉、机器学习<\/span>\n<\/div>\n\n<div class=\"content\">\n<p>最近投了一堆机器学习 \/ 深度学习 \/ 计算机视觉方向的公司，分享一下自己的经验，希望对大家有帮助。<\/p>\r\n<p>个人背景： 华科本科 + 港科大硕士（MPhil）<\/p>\r\n<p>拿到的 offer 有腾讯优图，阿里 AI lab，今日头条，滴滴研究院，商汤科技，旷视（face++），大疆，快手。绝大部分是 ssp（super special），给到了普通硕士能给到的最高档。<\/p>\r\n<p>（最新修改：经人提醒，我意识到直接 po 公司的原题是非常不好的行为。所以我修改一下答案，只能指明大概的考察范围。在此对我的所有面试官表示抱歉，未经同意贴出了所有的面试题。）<\/p>\r\n<p>-<\/p>\r\n<p>写在前面的话：<\/p>\r\n<p>这个回答的适用对象主要还是本科和硕士。PhD 找工作的套路跟硕士还是很不一样的，所以这个回答的经验对于手握几篇一作顶会的 PhD 大神并没啥参考意义。<\/p>\r\n<p>我也和我们实验室几个找工作的 PhD 学长学姐聊过，他们的面试主要是讲自己的 research，有的甚至就是去公司给个 talk，跟本科硕士的校招流程完全不同。现在也是 AI 方向 PhD 的黄金时代，没毕业就被各大公司主动联系，待遇也比我这种硕士高很多很多。<\/p>\r\n<p>一. 整体建议<\/p>\r\n<p>一定要找内推。<\/p>\r\n<p>内推一般有两种，第一种力度比较弱，在公司的内推系统上填一下你的名字，加快一下招聘流程；第二种力度比较强，直接把简历送到部门负责人手上。个人比较建议第二种，会省事很多。<\/p>\r\n<p>原因如下：<\/p>\r\n<p>（1）现在做机器学习的人实在太多了，在不找内推的情况下，流程会特别特别慢。即使你的简历比较优秀，也可能淹没在茫茫大海中，不一定能被懂行的人看到。<\/p>\r\n<p>（2）现在很多公司的笔试其实挺有难度的，就算是大神也有翻车的可能性。<\/p>\r\n<p>（3）对于大公司而言，即使通过了简历筛选、笔试那一关，你也很难保证你的简历被合适的部门挑中。很可能过关斩将后，发现给你安排的面试官并不是太对口。尤其是深度学习这样比较新的领域，一般部门的面试官多半也是近期自学的，对这个也是一知半解。所以如果是想去 BAT 这些大公司里面专门做 AI 的部门，按照正常校招流程走是不合适的，一定要找到那些部门的员工内推。<\/p>\r\n<p>在我看来，如果是跪在简历筛选、笔试这些上面，连面试官都没见到，就实在太可惜了。为了避免这一点，请认真找内推。最好能联系到你想去的公司部门里的负责人，直接安排面试。<\/p>\r\n<p>二. 面试经验<\/p>\r\n<p>面试遇到的题目，可以分为几个大类：<\/p>\r\n<p>（1）代码题（leetcode 类型），主要考察数据结构和基础算法，以及代码基本功<\/p>\r\n<p>虽然这部分跟机器学习，深度学习关系不大，但也是面试的重中之重。基本每家公司的面试都问了大量的算法题和代码题，即使是商汤、face++ 这样的深度学习公司，考察这部分的时间也占到了我很多轮面试的 60% 甚至 70% 以上。我去 face++ 面试的时候，面试官是 residual net，shuffle net 的作者；但他们的面试中，写代码题依旧是主要的部分。<\/p>\r\n<p>大部分题目都不难，基本是 leetcode medium 的难度。但是要求在现场白板编程，思路要流畅，能做到一次性 Bug-free. 并且，一般都是要给出时间复杂度和空间复杂度最优的做法。对于少数难度很大的题，也不要慌张。一般也不会一点思路也没有，尽力给面试官展现自己的思考过程。面试官也会引导你，给一点小提示，沿着提示把题目慢慢做出来也是可以通过面试的。<\/p>\r\n<p>我所遇到的一些需要当场写出完整代码的题目，部分有些是 LeetCode 原题，在这里我简单地举几个例子，附上 LeetCode 题目链接：<\/p>\r\n<p><a href=\"https:\/\/leetcode.com\/problems\/maximum-product-subarray\/description\/\">Maximum Product Subarray<\/a><\/p>\r\n<p><a href=\"https:\/\/leetcode.com\/problems\/maximal-square\/description\/\">Maximal Square<\/a><\/p>\r\n<p><a href=\"https:\/\/leetcode.com\/problems\/subsets\/description\/\">Subsets<\/a><\/p>\r\n<p>（直接贴具体的面试原题是非常不好的行为，该部分不在回答里放出来了。）<\/p>\r\n<p>（2）数学题或者\"智力\"题。<\/p>\r\n<p>不会涉及特别高深的数学知识，一般就是工科数学（微积分，概率论，线性代数）和一些组合数学的问题。<\/p>\r\n<p>这部分有些题也在知乎上被讨论过，这里附上相应的知乎链接：<\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/38331955\">如果一个女生说，她集齐了十二个星座的前男友，我们应该如何估计她前男友的数量？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/21605094\">如何理解矩阵的「秩」？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/28630628\">矩阵低秩的意义?<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/21874816\">如何理解矩阵特征值？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/22237507\">奇异值的物理意义是什么？<\/a><\/p>\r\n<p><a href=\"https:\/\/zhuanlan.zhihu.com\/p\/24913912\">为什么梯度反方向是函数值下降最快的方向？<\/a><\/p>\r\n<p>（3）机器学习基础<\/p>\r\n<p>这部分建议参考周志华老师的《机器学习》。<\/p>\r\n<p>列一下考察的知识点，并附上相关的优质知乎讨论。<\/p>\r\n<p>逻辑回归，SVM，决策树<\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/24904422\">逻辑回归和 SVM 的区别是什么？各适用于解决什么问题？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/26768865\">Linear SVM 和 LR 有什么异同？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/22290096\">SVM（支持向量机）属于神经网络范畴吗？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/34075616\">如何理解决策树的损失函数?<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/26726794\">各种机器学习的应用场景分别是什么？例如，k 近邻,贝叶斯，决策树，svm，逻辑斯蒂回归和最大熵模型。<\/a><\/p>\r\n<p>主成分分析，奇异值分解<\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/34143886\">SVD 降维体现在什么地方？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/47121788\">为什么 PCA 不被推荐用来避免过拟合？<\/a><\/p>\r\n<p>随机森林，GBDT, 集成学习<\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/26760839\">为什么说 bagging 是减少 variance，而 boosting 是减少 bias?<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/46784781\">基于树的 adaboost 和 Gradient Tree Boosting 区别？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/41354392\">机器学习算法中 GBDT 和 XGBOOST 的区别有哪些？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/51818176\">为什么在实际的 kaggle 比赛中 gbdt 和 random forest 效果非常好？<\/a><\/p>\r\n<p>过拟合<\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/59201590\">机器学习中用来防止过拟合的方法有哪些？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/20700829\">机器学习中使用「正则化来防止过拟合」到底是一个什么原理？为什么正则化项就可以防止过拟合？<\/a><\/p>\r\n<p>（4）深度学习基础<\/p>\r\n<p>这部分的准备，我推荐花书（Bengio 的 Deep learning）和 @魏秀参 学长的<a href=\"http:\/\/210.28.132.67\/weixs\/book\/CNN_book.html\">《解析卷积神经网络 - 深度学习实践手册》<\/a><\/p>\r\n<p>列一下大概的考察点和相关的知乎讨论。<\/p>\r\n<p>卷积神经网络，循环神经网络，LSTM 与 GRU，梯度消失与梯度爆炸，激活函数，防止过拟合的方法，dropout，batch normalization，各类经典的网络结构，各类优化方法<\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/39022858\">卷积神经网络工作原理直观的解释？<\/a><\/p>\r\n<p><a href=\"https:\/\/zhuanlan.zhihu.com\/p\/31575074\">卷积神经网络的复杂度分析<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/34681168\">CNN(卷积神经网络)、RNN(循环神经网络)、DNN(深度神经网络)的内部网络结构有什么区别？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/49812013\">bp 算法中为什么会产生梯度消失？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/38677354\">梯度下降法是万能的模型训练算法吗？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/34878706\">LSTM 如何来避免梯度弥散和梯度爆炸？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/42115548\">sgd 有多种改进的形式(rmsprop,adadelta 等),为什么大多数论文中仍然用 sgd?<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/41631631\">你有哪些 deep learning（rnn、cnn）调参的经验？<\/a><\/p>\r\n<p><a href=\"https:\/\/zhuanlan.zhihu.com\/p\/32230623\">Adam 那么棒，为什么还对 SGD 念念不忘 (1)<\/a><\/p>\r\n<p><a href=\"https:\/\/zhuanlan.zhihu.com\/p\/32262540\">Adam 那么棒，为什么还对 SGD 念念不忘 (2)<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/41037974\">全连接层的作用是什么？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/38102762\">深度学习中 Batch Normalization 为什么效果好？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/43370067\">为什么现在的 CNN 模型都是在 GoogleNet、VGGNet 或者 AlexNet 上调整的？<\/a><\/p>\r\n<p><a href=\"https:\/\/www.zhihu.com\/question\/28720729\">Krizhevsky 等人是怎么想到在 CNN 里用 Dropout 和 ReLu 的?<\/a><\/p>\r\n<p>（5）科研上的开放性问题<\/p>\r\n<p>这部分的问题没有固定答案，也没法很好地针对性准备。功在平时，多读 paper 多思考，注意培养自己的 insight 和 intuition。<\/p>\r\n<p>这部分在知乎上也有很多讨论，不具体列了。<\/p>\r\n<p>（6） 编程语言、操作系统等方面的一些问题。<\/p>\r\n<p>C++， Python， 操作系统，Linux 命令等等。这部分问得比较少，但还是有的，不具体列了<\/p>\r\n<p>（7）针对简历里项目 \/ 论文 \/ 实习的一些问题。<\/p>\r\n<p>这部分因人而异，我个人的对大家也没参考价值，也不列了。<\/p>\r\n<p>三. 平时应该怎么准备<\/p>\r\n<p>在大多数情况下，你能拿到什么样的 offer，其实已经被你的简历决定了。如果平时没有积累相关的经历和成果，很难只靠面试表现就拿到非常好的 offer。所以建议大家平时积累算法岗所看重的一些干货。<\/p>\r\n<p>下面几点算是找 AI 相关工作的加分项：<\/p>\r\n<p>（1）一作的顶级会议论文<\/p>\r\n<p>（2）AI 领域知名公司的实习经历（长期实习更好）<\/p>\r\n<p>（3）相关方向有含金量的项目经历<\/p>\r\n<p>（4）计算机视觉竞赛，数据挖掘竞赛的获奖或者优秀名次。现在这类竞赛太多了，就不具体列了。<\/p>\r\n<p>（5）程序设计竞赛的获奖（例如 OI\/ACM\/topcoder 之类的）<\/p>\r\n<p>当然，名校、高 GPA 这些是针对所有领域都有用的加分项，同样也是适用于这个领域的。<\/p>\r\n<p>所以我的建议就是，如果自己所在的实验室很厉害，资源丰富，就专心做科研，发 paper； 如果所在的实验室一般，没法产出相关的优秀成果，可以考虑自己做比赛和找实习。有一份知名公司的实习经历之后，找工作难度会下降很多。<\/p>\r\n<p>最后，祝有志于 AI 这个领域的人都能拿到满意的 offer。<\/p>\n<\/div>\n<\/div>\n\n\n<div class=\"view-more\"><a href=\"http:\/\/www.zhihu.com\/question\/59683332\">查看知乎讨论<span class=\"js-question-holder\"><\/span><\/a><\/div>\n\n<\/div>\n\n\n\n\n\n<div class=\"question\">\n<h2 class=\"question-title\">2018 年应届博士毕业生如何拿到知名互联网公司深度学习 offer？<\/h2>\n\n<div class=\"answer\">\n\n<div class=\"meta\">\n<img class=\"avatar\" src=\"http:\/\/pic1.zhimg.com\/45906afa0_is.jpg\">\n<span class=\"author\">孙尚香，<\/span><span class=\"bio\">shallow learning<\/span>\n<\/div>\n\n<div class=\"content\">\n<p>美帝 top 100 cs 机器学习 phd, 顶会若干，九月份开始找工作，十一月份求职结束。<\/p>\r\n<p>美国的大公司过程基本和硕士没什么区别， 需要刷 leetcode 过面试， 最多加一轮讲自己的研究什么的。只有极少数几个纯研究部门，比如 FAIR, MSR, Google Brain 这种可能不需要刷题，但是门槛很高，需要有很好的研究成果，而且还需要有很不错的 connection。所以目标是这些的话开会很重要，不光可以介绍自己的结果，还可以 networking。 其它和硕士 \/ 本科的区别就是最终 offer 会高一些，定级会比应届硕士高一级， team match 容易 match 到不错的组。大公司的入门等级一般不能谈，但是同一个等级 offer 可以差很多，多拿 competing offer 吧。 startup 没有面试过，不了解。<\/p>\r\n<p>也面过一些中国的公司，比如阿里的 ai lab, 招聘门槛就低了一些，面试都是电话，过程就是聊天，问的问题也比较基础，两三个电话就结束了。 感觉就是看过觉得简历没什么问题，打电话看看这个人是不是正常就结束了。但是 face++ 商汤这种 hot startup 没有面试过，不了解。<\/p>\r\n<p>还有就是中国在美国的研究院，比如京东在 MTV, 阿里腾讯在西雅图，一般都是通过猎头招聘，面试门槛介于中间，基本纯聊 research, 不需要刷题，工资开的不错。<\/p>\r\n<p>大概就这些吧。<\/p>\r\n<p>-<\/p>\r\n<ol><li>其实大厂对深度学习的需求量感觉并不高，比如 flg 面试的时候没有任何涉及深度学习的问题，原因可能是用深度学习落地的产品并不多，也可能是目前的人就差不多够用了，招的需求也没那么强。当然 research 岗是另外一个 track,招的人太少并且门槛很高，没什么讨论的价值，目标是这些的也不会上来问这个问题了。相反一些直接指望利用深度学习做产品的 startup,国内的比如商汤，face++, 美国的比如一票做无人驾驶的，做图像识别的, 做医疗图像的，深度学习的面试会更专业。这个就各有所求了。<\/li>\r\n<li>店面除了 linkedin 统统 leetcode，跟 ml 没任何关系，更何况深度学习了。拿到店面要有 refer 或者猎头推，学校不是特别好的话海投基本不要指望有任何回复。<\/li>\r\n<li>大厂的 headcount 一般都是年初开放，不要把主力公司的面试放到年底，血泪的教训。 有些公司内推都没拿到面试（g 内推没有面试因为没应届的 hc 了）。 有些只剩一两个 hc 的要求也会变的比年初高, 比如 L，面完感觉很不错，结果也是三到四个 hire 或者 strong hire,一到两个 neutral, 送 hiring committee 没有过，recruiter 告诉我早几个月过没问题的，当然也可能是安慰我。<\/li>\r\n<li>amazon 的 applied rs 面试相对比较奇葩，组在面试前就定好了，会有一面是讲自己 research 的，一面讲怎么解决他们产品上的问题的，一面是 general ml 的问题，一面是 behavior+ 简单 leetcode, 还有一面是 coding。 这个需要准备下别的问题。别的厂统统都是两到三个 leetcode 加一个 recommendation system 或者 ranking 的 ml design。 面到后面都讲吐了。<\/li>\r\n<\/ol><p>总之刷题是王道，别的暂时没想起啥了……<\/p>\n<\/div>\n<\/div>\n\n\n<div class=\"view-more\"><a href=\"http:\/\/www.zhihu.com\/question\/264519020\">查看知乎讨论<span class=\"js-question-holder\"><\/span><\/a><\/div>\n\n<\/div>\n\n\n<\/div>\n<\/div><script type=“text\/javascript”>window.daily=true<\/script>",
  "image_source": "Public Domain",
  "title": "见过不少人用这个头像哈哈。。。原创作者在这里哦",
  "image": "https:\/\/pic4.zhimg.com\/v2-e798fead558776a633e3d4131cec68cb.jpg",
  "share_url": "http:\/\/daily.zhihu.com\/story\/9663965",
  "js": [],
  "ga_prefix": "011507",
  "images": [
    "https:\/\/pic3.zhimg.com\/v2-23e42514bb619b43eec2f3a3379e1df6.jpg"
  ],
  "type": 0,
  "id": 9663965,
  "css": [
    "http:\/\/news-at.zhihu.com\/css\/news_qa.auto.css?v=4b3e3"
  ]
}